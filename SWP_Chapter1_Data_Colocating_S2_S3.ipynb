{"cells":[{"cell_type":"markdown","metadata":{"id":"WILcaKrnOYm2"},"source":["# Colocating Sentinel-3 OLCI and Sentinal-2 Optical Data\n","In this section, we embark on a detailed exploration of colocating Sentinel-3 OLCI (Ocean and Land Colour Instrument) data with Sentinel-2 optical data. Colocation of data from these two satellite missions enables a powerful synergy, harnessing the high spatial resolution of Sentinel-2 and the comprehensive coverage and colocated altimeter data from Sentinel-3. This fusion of datasets provides a richer, more detailed perspective of Earth's surface.\n","\n","In the following sections, we will guide you through the necessary steps to efficiently identify and align these datasets."]},{"cell_type":"markdown","metadata":{"id":"Xpf4njVUOYm5"},"source":["## Step 0: Read in Functions Needed\n","\n","To streamline our data fetching and processing, we'll first load the essential functions. These functions are designed to handle various tasks such as data retrieval, format conversion, and preliminary data processing. Ensure that you've imported all the required functions before proceeding to the next steps of the workflow. All functions have docstrings so please read them to get some ideas of what they do.\n"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ckBVbzLdo9I7","executionInfo":{"status":"ok","timestamp":1706873419365,"user_tz":0,"elapsed":23764,"user":{"displayName":"Skylar Park","userId":"17855320419104885667"}},"outputId":"612a676f-19e9-478d-b8f7-6433668b77c7"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","execution_count":2,"metadata":{"id":"3PYA2V5AOYm5","executionInfo":{"status":"ok","timestamp":1706873435426,"user_tz":0,"elapsed":14714,"user":{"displayName":"Skylar Park","userId":"17855320419104885667"}}},"outputs":[],"source":["import ee\n","from datetime import datetime, timedelta\n","from shapely.geometry import Polygon, Point\n","import numpy as np\n","import subprocess\n","import requests\n","import pandas as pd\n","import os\n","\n","ee.Authenticate()\n","ee.Initialize(project='week3fetchdata-412109')\n","\n","def get_matched_S2_image_ids(s3_image,boundary_geometry):\n","        s3_time = datetime.utcfromtimestamp(s3_image.get('system:time_start').getInfo() / 1000)\n","\n","        # Define a time window for S2 search (Â±3 hours from S3 image time)\n","        start_time = s3_time - timedelta(hours=3)\n","        end_time = s3_time + timedelta(hours=3)\n","\n","        # Query for S2 images within the time window and spatial extent of S3\n","        S2_collection = ee.ImageCollection('COPERNICUS/S2') \\\n","        .filterDate(start_time, end_time) \\\n","        .filterBounds(boundary_geometry)\n","\n","        # Return the list of S2 image IDs\n","        return S2_collection.aggregate_array('system:index').getInfo()\n","\n","\n","def find_matched_satellite_images(S3_date_range, S3_spatial_extent, boundary_geometry):\n","    \"\"\"\n","    Function to find matched Sentinel-2 image IDs for each Sentinel-3 image in the given date range and spatial extent.\n","    \"\"\"\n","\n","    # Define variables for Sentinel-3 query\n","    S3_product = 'COPERNICUS/S3/OLCI'\n","\n","    # Query for Sentinel-3 data\n","    S3_collection = ee.ImageCollection(S3_product) \\\n","        .filterDate(S3_date_range[0], S3_date_range[1]) \\\n","        .filterBounds(boundary_geometry)\n","\n","    # Convert S3_collection to a list of image IDs\n","    S3_image_ids = S3_collection.aggregate_array('system:index').getInfo()\n","\n","    # List to store matched pairs\n","    matched_pairs = []\n","\n","    # Loop through each S3 image ID and find matching S2 images\n","    for s3_image_id in S3_image_ids:\n","        s3_image = ee.Image(S3_collection.filter(ee.Filter.eq('system:index', s3_image_id)).first())\n","        matched_S2_image_ids = get_matched_S2_image_ids(s3_image,boundary_geometry)\n","\n","        # Record each pair of matched S3 and S2 images\n","        for s2_image_id in matched_S2_image_ids:\n","            matched_pairs.append((s3_image_id, s2_image_id))\n","\n","    return matched_pairs\n","\n","def parse_gee_filename(gee_filename):\n","    \"\"\"\n","    Parses the Google Earth Engine filename to extract satellite name, sensing date, and start time.\n","\n","    Parameters:\n","    gee_filename (str): Filename obtained from Google Earth Engine.\n","\n","    Returns:\n","    tuple: Contains satellite name, sensing date, and start time.\n","    \"\"\"\n","    parts = gee_filename.split('_')\n","    sensing_date = parts[0]\n","    tile_number = parts[2]\n","    return sensing_date, tile_number\n","\n","def parse_gee_filename_s3(gee_filename):\n","    \"\"\"\n","    Parses the Google Earth Engine filename to extract satellite name, sensing date, and start time.\n","\n","    Parameters:\n","    gee_filename (str): Filename obtained from Google Earth Engine.\n","\n","    Returns:\n","    tuple: Contains satellite name, sensing date, and start time.\n","    \"\"\"\n","    parts = gee_filename.split('_')\n","    satellite = parts[0] + '_OL_1_EFR'\n","    start_datetime = parts[1]\n","    end_datetime = parts[2]\n","\n","    # Extract date from the start_datetime (assuming the format is like '20180601T014926')\n","    sensing_date = start_datetime[:8]\n","    start_time = start_datetime[9:]\n","\n","    return satellite, sensing_date, start_time\n","\n","# Function to get an access token\n","def get_access_token(username, password):\n","    \"\"\"\n","    Retrieves access token from Copernicus Dataspace using the provided credentials.\n","\n","    Parameters:\n","    username (str): Username for Copernicus Dataspace.\n","    password (str): Password for Copernicus Dataspace.\n","\n","    Returns:\n","    str: Access token for authenticated sessions.\n","    \"\"\"\n","    url = 'https://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token'\n","    data = {\n","        'grant_type': 'password',\n","        'username': username,\n","        'password': password,\n","        'client_id': 'cdse-public'\n","    }\n","    response = requests.post(url, data=data)\n","    response.raise_for_status()\n","    return response.json()['access_token']\n","\n","\n","# Function to query Sentinel-2 data from Copernicus Data Space\n","def query_sentinel2_data(sensing_start_date, tile_number, token):\n","    \"\"\"\n","    Queries the Sentinel-2 data from the Copernicus Data Space based on sensing start date, tile number, and access token.\n","\n","    Parameters:\n","    sensing_start_date (str): The start date and time for the data sensing in the format 'YYYYMMDDTHHMMSS'.\n","    tile_number (str): The specific tile number of the Sentinel-2 data to be queried.\n","    token (str): The access token for authenticating requests to the Copernicus Data Space.\n","\n","    Returns:\n","    DataFrame: A DataFrame containing the query results with details about the Sentinel-2 data.\n","\n","    The function constructs a query URL with specified parameters, sends a request to the Copernicus Data Space,\n","    and returns the results as a DataFrame. It filters the data based on the tile number and the content start date\n","    within a certain time window.\n","    \"\"\"\n","    # Convert sensing_start_date to datetime object and format it for the query\n","    start_time = datetime.strptime(sensing_start_date, '%Y%m%dT%H%M%S')\n","    end_time = start_time + timedelta(hours=2)  # Adjust the time window as necessary\n","    start_time_str = start_time.strftime('%Y-%m-%dT%H:%M:%SZ')\n","    end_time_str = end_time.strftime('%Y-%m-%dT%H:%M:%SZ')\n","\n","    # Construct the request URL with the contains function for tile number\n","    url = f\"https://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=contains(Name,'{tile_number}') and Collection/Name eq 'SENTINEL-2' and ContentDate/Start gt {start_time_str} and ContentDate/Start lt {end_time_str}\"\n","    headers = {'Authorization': f'Bearer {token}'}\n","\n","    # Make the API request\n","    response = requests.get(url, headers=headers)\n","    response.raise_for_status()\n","\n","    return pd.DataFrame.from_dict(response.json()['value'])\n","\n","def extract_correct_product_name(df, start_time, tile_number):\n","    \"\"\"\n","    Extracts the correct product name and ID from a dataframe based on a specific start time and tile number.\n","\n","    Parameters:\n","    df (DataFrame): The dataframe containing product information.\n","    start_time (str): The start time used to filter the products.\n","    tile_number (str): The tile number used to filter the products.\n","\n","    Returns:\n","    tuple: A tuple containing the first matching product name and ID, or (None, None) if no match is found.\n","    \"\"\"\n","    # Adjusted regex pattern to match the filename format\n","    pattern = f'MSIL1C.*{start_time}.*_{tile_number}_'\n","    filtered_products = df[df['Name'].str.contains(pattern, regex=True)]\n","\n","\n","    # Return the first matching product name, or None if not found\n","    return filtered_products['Name'].iloc[0] if not filtered_products.empty else None, filtered_products['Id'].iloc[0] if not filtered_products.empty else None\n","\n","def process_image_pair(s2_ee_image_id, token):\n","    \"\"\"\n","    Processes a pair of Sentinel-2 images by querying the Copernicus Data Space to find the corresponding product name and ID.\n","\n","    Parameters:\n","    s2_ee_image_id (str): The Sentinel-2 Earth Engine image ID.\n","    token (str): The access token for authenticating requests to the Copernicus Data Space.\n","\n","    Returns:\n","    tuple: A tuple containing the product name and ID for the corresponding Sentinel-2 image.\n","    \"\"\"\n","    sensing_start_date = s2_ee_image_id.split('_')[0]\n","    tile_number = s2_ee_image_id.split('_')[2]\n","\n","    # Query the Copernicus Data Space\n","    df = query_sentinel2_data(sensing_start_date, tile_number, token)\n","\n","    # Extract the correct MSIL1C product name\n","    return extract_correct_product_name(df, sensing_start_date, tile_number)\n","\n","def download_single_product(product_id, file_name, access_token, download_dir=\"downloaded_products\"):\n","    \"\"\"\n","    Download a single product from the Copernicus Data Space.\n","\n","    :param product_id: The unique identifier for the product.\n","    :param file_name: The name of the file to be downloaded.\n","    :param access_token: The access token for authorization.\n","    :param download_dir: The directory where the product will be saved.\n","    \"\"\"\n","    # Ensure the download directory exists\n","    os.makedirs(download_dir, exist_ok=True)\n","\n","    # Construct the download URL\n","    url = f\"https://zipper.dataspace.copernicus.eu/odata/v1/Products({product_id})/$value\"\n","\n","    # Set up the session and headers\n","    headers = {\"Authorization\": f\"Bearer {access_token}\"}\n","    session = requests.Session()\n","    session.headers.update(headers)\n","\n","    # Perform the request\n","    response = session.get(url, headers=headers, stream=True)\n","\n","    # Check if the request was successful\n","    if response.status_code == 200:\n","        # Define the path for the output file\n","        output_file_path = os.path.join(download_dir, file_name + \".zip\")\n","\n","        # Stream the content to a file\n","        with open(output_file_path, \"wb\") as file:\n","            for chunk in response.iter_content(chunk_size=8192):\n","                if chunk:\n","                    file.write(chunk)\n","        print(f\"Downloaded: {output_file_path}\")\n","    else:\n","        print(f\"Failed to download product {product_id}. Status Code: {response.status_code}\")\n","\n","def query_sentinel3_olci_data(satellite, sensing_date, start_time, token):\n","    \"\"\"\n","    Queries Sentinel-3 OLCI data from Copernicus Data Space based on satellite name, sensing date, and start time.\n","\n","    Parameters:\n","    satellite (str): Name of the satellite.\n","    sensing_date (str): Date of the data sensing.\n","    start_time (str): Start time of the data sensing.\n","    token (str): Access token for authentication.\n","\n","    Returns:\n","    DataFrame: A DataFrame containing the query results with details about the Sentinel-3 OLCI data.\n","    \"\"\"\n","    # Convert sensing_date to datetime object and format it for the query\n","    sensing_datetime = datetime.strptime(f'{sensing_date}T{start_time}', '%Y%m%dT%H%M%S')\n","    sensing_datetime = sensing_datetime - timedelta(seconds=1)\n","\n","    # Construct the request URL using the filter structure provided\n","    url = (\n","        f\"https://catalogue.dataspace.copernicus.eu/odata/v1/Products?\"\n","        f\"$filter=contains(Name,'{satellite}') and \"\n","        f\"ContentDate/Start ge {sensing_datetime.strftime('%Y-%m-%dT%H:%M:%S.000Z')} and \"\n","        f\"ContentDate/Start le {(sensing_datetime + timedelta(days=1)).strftime('%Y-%m-%dT%H:%M:%S.000Z')}&\"\n","        f\"$orderby=ContentDate/Start&$top=1000\"\n","    )\n","    headers = {'Authorization': f'Bearer {token}'}\n","\n","    # Print the URL for debugging\n","    print(url)\n","\n","    # Make the API request\n","    response = requests.get(url, headers=headers)\n","    # Check if the request was successful\n","    if response.status_code != 200:\n","        # Print error details and return an empty DataFrame if the request failed\n","        print(f\"Error: Unable to fetch data. Status Code: {response.status_code}. Response: {response.text}\")\n","        return pd.DataFrame()\n","\n","    # Convert the JSON response to a DataFrame\n","    search_results_df = pd.DataFrame.from_dict(response.json()['value'])\n","\n","    # Convert the 'ContentDate/Start' to datetime objects and sort the results\n","    search_results_df['SensingStart'] = pd.to_datetime(search_results_df['ContentDate'].apply(lambda x: x['Start']))\n","    search_results_df.sort_values(by='SensingStart', inplace=True)\n","\n","    return search_results_df\n","\n","\n","\n","def fetch_S3_images_by_area_and_date(date_range, spatial_extent, area_of_interest):\n","    \"\"\"\n","    Fetches Sentinel-3 OLCI images based on a specified date range and area of interest.\n","\n","    :param date_range: List containing the start and end dates (e.g., ['2018-06-01', '2018-06-02'])\n","    :param spatial_extent: List containing the spatial extent [min_lon, min_lat, max_lon, max_lat]\n","    :param area_of_interest: ee.Geometry object defining the specific area for which to fetch images\n","\n","    :return: List of dictionaries, each containing details about a fetched image, including its ID, date, and download URL.\n","    \"\"\"\n","    # Initialize the Earth Engine module\n","    ee.Initialize()\n","\n","    # Define variables for Sentinel-3 OLCI query\n","    S3_product = 'COPERNICUS/S3/OLCI'\n","\n","    # Query for Sentinel-3 data within the specified date range and area of interest\n","    S3_collection = ee.ImageCollection(S3_product) \\\n","        .filterDate(date_range[0], date_range[1]) \\\n","        .filterBounds(area_of_interest)\n","\n","    # Convert S3_collection to a list of image IDs\n","    S3_image_ids = S3_collection.aggregate_array('system:index').getInfo()\n","    S3_images_info = S3_collection.getInfo()['features']\n","\n","    # Initialize an empty list to store details\n","    S3_image_details = []\n","\n","    # Iterate through each image in the collection\n","    for img_info in S3_images_info:\n","        # Fetch image ID\n","        image_id = img_info['id']\n","\n","        # Fetch image date and other properties as needed\n","        image_date = img_info['properties']['system:time_start']  # Example property\n","\n","        # Append the details to the list\n","        S3_image_details.append({\n","            'id': image_id,\n","            'date': image_date\n","        })\n","\n","    return S3_image_details\n","\n","def get_s2_images_in_arctic(start_date, end_date, max_cloud_percentage=10):\n","    \"\"\"\n","    Retrieves Sentinel-2 images within the Arctic region for a specified date range and cloud coverage limit.\n","\n","    Parameters:\n","    start_date (str): The starting date for the image collection in 'YYYY-MM-DD' format.\n","    end_date (str): The ending date for the image collection in 'YYYY-MM-DD' format.\n","    area (ee.Geometry): The geographical area within which to filter the Sentinel-2 images.\n","    max_cloud_percentage (float, optional): The maximum cloud coverage percentage for filtering images.\n","                                            Defaults to 10 percent.\n","\n","    Returns:\n","    ee.ImageCollection: A collection of Sentinel-2 images that fall within the specified date range,\n","                        cloud coverage limit, and geographical area.\n","    \"\"\"\n","    # Define the Arctic region bounding box\n","    arctic_region = ee.Geometry.Rectangle([-180, 60, 180, 90])\n","\n","    # Filter the Sentinel-2 collection\n","    s2_collection = ee.ImageCollection('COPERNICUS/S2') \\\n","        .filterDate(start_date, end_date) \\\n","        .filterBounds(arctic_region) \\\n","        .filter(ee.Filter.lt('CLOUDY_PIXEL_PERCENTAGE', max_cloud_percentage))\n","\n","    return s2_collection\n","\n","\n","def find_colocated_s3_for_s2(s2_image, buffer_distance=10000, time_window_hours=2):\n","    \"\"\"\n","    Finds Sentinel-3 images that are temporally and spatially colocated with a given Sentinel-2 image.\n","\n","    Parameters:\n","    s2_image (ee.Image): The Sentinel-2 image to use as a reference for finding colocated Sentinel-3 images.\n","    buffer_distance (int, optional): The buffer distance in meters to apply to the footprint of the Sentinel-2 image.\n","                                     Defaults to 10,000 meters.\n","    time_window_hours (int, optional): The time window in hours to search for Sentinel-3 images before and after\n","                                       the Sentinel-2 image's acquisition time. Defaults to 2 hours.\n","\n","    Returns:\n","    ee.List: A list of Sentinel-3 images that are within the specified time window and overlapping\n","             the buffered footprint of the provided Sentinel-2 image.\n","    \"\"\"\n","    # Buffer the S2 footprint and define time window\n","    s2_geometry = s2_image.geometry().buffer(buffer_distance)\n","    s2_time = ee.Date(s2_image.get('system:time_start'))\n","    start_time = s2_time.advance(-time_window_hours, 'hour')\n","    end_time = s2_time.advance(time_window_hours, 'hour')\n","\n","    # Query for S3 images\n","    s3_collection = ee.ImageCollection('COPERNICUS/S3/OLCI') \\\n","        .filterDate(start_time, end_time) \\\n","        .filterBounds(s2_geometry)\n","\n","    return s3_collection.toList(s3_collection.size())\n"]},{"cell_type":"markdown","metadata":{"id":"jTlXPfKPOYm7"},"source":["## Step 1: Get the Pairs of Colocated S2/S3\n","\n","Once you have set up your environment and are authenticated with Google Earth Engine, the next step is to extract the matched filenames that meet your specific criteria. This involves querying the Google Earth Engine datasets based on your area of interest, time frame, and any other relevant parameters. We will get a list of matched filenames but we only select one of them to downlaod. The code snippet below demonstrates how to perform this task effectively:"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"mn1aLMqNOYm7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706873439434,"user_tz":0,"elapsed":4012,"user":{"displayName":"Skylar Park","userId":"17855320419104885667"}},"outputId":"0b22b6b8-c3f6-4583-f2cc-b0a2c87aa50e"},"outputs":[{"output_type":"stream","name":"stdout","text":["S2 Image: COPERNICUS/S2/20190301T235611_20190301T235610_T01WCM has colocated S3 Image: COPERNICUS/S3/OLCI/S3A_20190301T222350_20190301T222650\n","S2 Image: COPERNICUS/S2/20190301T235611_20190301T235610_T01WCM has colocated S3 Image: COPERNICUS/S3/OLCI/S3B_20190301T232521_20190301T232821\n","S2 Image: COPERNICUS/S2/20190301T235611_20190301T235610_T01WCS has colocated S3 Image: COPERNICUS/S3/OLCI/S3A_20190301T222350_20190301T222650\n","S2 Image: COPERNICUS/S2/20190301T235611_20190301T235610_T01WCS has colocated S3 Image: COPERNICUS/S3/OLCI/S3A_20190302T000449_20190302T000749\n","S2 Image: COPERNICUS/S2/20190301T235611_20190301T235610_T01WCS has colocated S3 Image: COPERNICUS/S3/OLCI/S3B_20190301T232521_20190301T232821\n","S2 Image: COPERNICUS/S2/20190301T235611_20190301T235610_T01WCT has colocated S3 Image: COPERNICUS/S3/OLCI/S3A_20190301T222350_20190301T222650\n","S2 Image: COPERNICUS/S2/20190301T235611_20190301T235610_T01WCT has colocated S3 Image: COPERNICUS/S3/OLCI/S3A_20190302T000449_20190302T000749\n","S2 Image: COPERNICUS/S2/20190301T235611_20190301T235610_T01WCT has colocated S3 Image: COPERNICUS/S3/OLCI/S3B_20190301T232521_20190301T232821\n","S2 Image: COPERNICUS/S2/20190301T235611_20190301T235610_T01WCU has colocated S3 Image: COPERNICUS/S3/OLCI/S3A_20190301T222350_20190301T222650\n","S2 Image: COPERNICUS/S2/20190301T235611_20190301T235610_T01WCU has colocated S3 Image: COPERNICUS/S3/OLCI/S3A_20190302T000449_20190302T000749\n","S2 Image: COPERNICUS/S2/20190301T235611_20190301T235610_T01WCU has colocated S3 Image: COPERNICUS/S3/OLCI/S3B_20190301T232521_20190301T232821\n","S2 Image: COPERNICUS/S2/20190301T235611_20190301T235610_T01WCV has colocated S3 Image: COPERNICUS/S3/OLCI/S3A_20190301T222350_20190301T222650\n","S2 Image: COPERNICUS/S2/20190301T235611_20190301T235610_T01WCV has colocated S3 Image: COPERNICUS/S3/OLCI/S3B_20190301T232521_20190301T232821\n","S2 Image: COPERNICUS/S2/20190301T235611_20190301T235610_T60WWD has colocated S3 Image: COPERNICUS/S3/OLCI/S3A_20190301T222350_20190301T222650\n","S2 Image: COPERNICUS/S2/20190301T235611_20190301T235610_T60WWD has colocated S3 Image: COPERNICUS/S3/OLCI/S3A_20190302T000449_20190302T000749\n","S2 Image: COPERNICUS/S2/20190301T235611_20190301T235610_T60WWD has colocated S3 Image: COPERNICUS/S3/OLCI/S3B_20190301T232521_20190301T232821\n"]}],"source":["ee.Initialize()\n","start_date = '2019-03-01'\n","end_date = '2019-03-02'\n","s2_collection = get_s2_images_in_arctic(start_date, end_date)\n","\n","# Iterate over S2 images and find colocated S3 images\n","matched_pairs = []\n","s2_list = s2_collection.toList(s2_collection.size()).getInfo()\n","for s2_info in s2_list:\n","    s2_image = ee.Image(s2_info['id'])\n","    colocated_s3 = find_colocated_s3_for_s2(s2_image)\n","    s3_info_list = colocated_s3.getInfo()\n","\n","    for s3_info in s3_info_list:\n","        matched_pairs.append((s2_info['id'], s3_info['id']))\n","\n","# Print or process the matched pairs\n","for pair in matched_pairs:\n","    print(\"S2 Image:\", pair[0], \"has colocated S3 Image:\", pair[1])"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"7hpqFbnPOYm8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706873539522,"user_tz":0,"elapsed":100094,"user":{"displayName":"Skylar Park","userId":"17855320419104885667"}},"outputId":"3c64c8cd-acd6-41e5-954d-102b8428c3a7"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloaded: /content/drive/MyDrive/GEOL0069/Week_4/Data/S2A_MSIL1C_20190301T235611_N0207_R116_T01WCU_20190302T014622.SAFE.zip\n","S2A_MSIL1C_20190301T235611_N0207_R116_T01WCU_20190302T014622.SAFE\n"]}],"source":["username = 'sunwoo2001@gmail.com'\n","password = 'Peacemaker28@!'\n","\n","token = get_access_token(username, password)\n","access_token = token\n","download_dir = '/content/drive/MyDrive/GEOL0069/Week_4/Data'\n","\n","gee_filename = '20190301T235611_20190301T235610_T01WCU'\n","token = get_access_token(username, password)\n","file_name, product_id = process_image_pair(gee_filename, token)\n","download_single_product(product_id, file_name, access_token, download_dir)\n","print(file_name)"]},{"cell_type":"markdown","metadata":{"id":"RHN22JfqOYm8"},"source":["### Proceeding with Sentinel-3 OLCI Download\n","\n","Moving forward, we turn our attention to downloading the Sentinel-3 OLCI data. The process mirrors the approach we took with Sentinel-2, maintaining consistency in our methodology. We'll apply the same logic of filename conversion and follow the structured steps to retrieve the data from the Copernicus dataspace."]},{"cell_type":"code","execution_count":5,"metadata":{"id":"H_hnoSnHOYm8","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706873590060,"user_tz":0,"elapsed":50544,"user":{"displayName":"Skylar Park","userId":"17855320419104885667"}},"outputId":"c4924307-68af-4f78-937b-f7d1fa58cf21"},"outputs":[{"output_type":"stream","name":"stdout","text":["https://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=contains(Name,'S3B_OL_1_EFR') and ContentDate/Start ge 2019-03-01T23:25:20.000Z and ContentDate/Start le 2019-03-02T23:25:20.000Z&$orderby=ContentDate/Start&$top=1000\n","S3B_OL_1_EFR____20190301T232521_20190301T232821_20190303T043409_0179_022_301_1800_LN1_O_NT_002.SEN3\n","Downloaded: /content/drive/MyDrive/GEOL0069/Week_4/Data/S3B_OL_1_EFR____20190301T232521_20190301T232821_20190303T043409_0179_022_301_1800_LN1_O_NT_002.SEN3.zip\n"]}],"source":["# Example GEE image ID\n","username = 'sunwoo2001@gmail.com'\n","password = 'Peacemaker28@!'\n","token = get_access_token(username, password)\n","gee_image_id = 'S3B_20190301T232521_20190301T232821'\n","# Parse the GEE filename to get the date and time\n","satellite, sensing_date, start_time = parse_gee_filename_s3(gee_image_id)\n","\n","# Query the Copernicus Data Space for the corresponding Sentinel-3 OLCI data\n","s3_olci_data = query_sentinel3_olci_data(satellite, sensing_date, start_time, token)\n","download_dir = '/content/drive/MyDrive/GEOL0069/Week_4/Data' # Replace with your desired download directory\n","product_id = s3_olci_data['Id'][0]\n","file_name = s3_olci_data['Name'][0]\n","print(file_name)\n","# Download the single product\n","download_single_product(product_id, file_name, access_token, download_dir)"]},{"cell_type":"markdown","metadata":{"id":"vGiEYKE5OYm8"},"source":["### Downloading Colocated Altimetry Data of Sentinel-3 OLCI\n","\n","The Sentinel-3 satellite offers an exceptional capability in Earth observation: the simultaneous acquisition of optical data from its OLCI instrument and altimetry measurements.  In this section, we will guide you through the process of downloading this colocated altimetry data alongside the Sentinel-3 OLCI optical data."]},{"cell_type":"code","execution_count":6,"metadata":{"id":"LUa_Jh0yOYm9","executionInfo":{"status":"ok","timestamp":1706873590061,"user_tz":0,"elapsed":20,"user":{"displayName":"Skylar Park","userId":"17855320419104885667"}}},"outputs":[],"source":["import requests\n","import pandas as pd\n","import subprocess\n","import os\n","import time\n","import shutil\n","import json\n","from datetime import date\n","from joblib import Parallel, delayed\n","import zipfile\n","import sys\n","import glob\n","import numpy as np\n","\n","def get_access_token(username, password):\n","    \"\"\"\n","    Obtain an access token to the Copernicus Data Space Ecosystem.\n","    Necessary for the download of hosted products.\n","    \"\"\"\n","    p =  subprocess.run(f\"curl --location --request POST 'https://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token' \\\n","            --header 'Content-Type: application/x-www-form-urlencoded' \\\n","            --data-urlencode 'grant_type=password' \\\n","            --data-urlencode 'username={username}' \\\n","            --data-urlencode 'password={password}' \\\n","            --data-urlencode 'client_id=cdse-public'\", shell=True,capture_output=True, text=True)\n","    access_dict = json.loads(p.stdout)\n","    return access_dict['access_token'], access_dict['refresh_token']\n","\n","#=============================================================================================================================================================#\n","\n","def get_new_access_token(refresh_token):\n","    \"\"\"\n","    Obtain a new access token to the Copernicus Data Space Ecosystem using a previously provided refesh token.\n","    \"\"\"\n","    p =  subprocess.run(f\"curl --location --request POST 'https://identity.dataspace.copernicus.eu/auth/realms/CDSE/protocol/openid-connect/token' \\\n","    --header 'Content-Type: application/x-www-form-urlencoded' \\\n","    --data-urlencode 'grant_type=refresh_token' \\\n","    --data-urlencode 'refresh_token={refresh_token}' \\\n","    --data-urlencode 'client_id=cdse-public'\", shell=True,capture_output=True, text=True)\n","    access_dict = json.loads(p.stdout)\n","    return access_dict['access_token'], access_dict['refresh_token']\n","\n","#=============================================================================================================================================================#\n","\n","def get_S3_SI_search_results_df(date):\n","    \"\"\"\n","    Obtain a pandas dataframe of Sentinel-3 sea ice thematic products for a given date.\n","    \"\"\"\n","    json = requests.get(f\"https://catalogue.dataspace.copernicus.eu/odata/v1/Products?$filter=Collection/Name eq 'SENTINEL-3' and Attributes/OData.CSC.StringAttribute/any(att:att/Name eq 'productType' and att/OData.CSC.StringAttribute/Value eq 'SR_2_LAN_SI') and Attributes/OData.CSC.StringAttribute/any(att:att/Name eq 'timeliness' and att/OData.CSC.StringAttribute/Value eq 'NT') and ContentDate/Start gt {(date-pd.Timedelta(days=1)).strftime('%Y-%m-%dT%H:%M:%SZ')} and ContentDate/End lt {(date+pd.Timedelta(days=2)).strftime('%Y-%m-%dT%H:%M:%SZ')}&$top=1000\").json()\n","\n","    results_df = pd.DataFrame.from_dict(json['value'])\n","    results_df['Satellite'] = [row['Name'][:3] for i,row in results_df.iterrows()]\n","    results_df['SensingStart'] = [pd.to_datetime(row['ContentDate']['Start']) for i,row in results_df.iterrows()]\n","    results_df['SensingEnd'] = [pd.to_datetime(row['ContentDate']['End']) for i,row in results_df.iterrows()]\n","    results_df =  results_df[(results_df['SensingEnd'] >= date) & (results_df['SensingStart'] <= date+pd.Timedelta(days=1))]\n","    results_df = results_df.sort_values(by='SensingStart')\n","    return results_df\n","\n","\n","#=============================================================================================================================================================#\n","\n","def filter_duplicate_products_versions(results_df, keep_latest=True ):\n","    \"\"\"\n","    Filter Sentinel-3 product dataframe to remove duplicate verions of files.\n","    By default, we keep the latest version of the file. E.g., where an operation version\n","    and a reprocessed version exists, we keep the reprocessed version.\n","    \"\"\"\n","    results_df['name_snippet'] = [row['Name'][:47] for i,row in results_df.iterrows()]\n","    if  keep_latest == True:\n","        keep='last'\n","    else:\n","        keep = 'first'\n","\n","    results_df = (\n","        results_df\n","        .sort_values(by='ModificationDate')\n","        .drop_duplicates(subset=['name_snippet'], keep=keep)\n","        .drop(columns = ['name_snippet'])\n","        .sort_values(by='SensingStart')\n","    )\n","\n","    return results_df\n","\n","def find_overlapping_sar(olci_filename, search_results_df):\n","    # Extract date and time from OLCI filename\n","    parts = olci_filename.split('_')\n","    olci_date_time = datetime.strptime(parts[7], '%Y%m%dT%H%M%S')\n","\n","    # Filter SAR filenames based on overlapping criteria\n","    # This is a placeholder logic, adjust according to your specific criteria\n","    overlapping_sar = search_results_df[search_results_df['Name'].apply(lambda x: 'S3' in x and 'SR_2_LAN_SI' in x)]\n","\n","    return overlapping_sar\n","\n","\n","def get_date_from_olci_filename(olci_filename):\n","    \"\"\"\n","    Extracts the date from an OLCI filename.\n","\n","    Parameters:\n","    olci_filename (str): The OLCI filename.\n","\n","    Returns:\n","    datetime.date: The date extracted from the filename.\n","    \"\"\"\n","    parts = olci_filename.split('_')\n","    date_str = parts[7][:8]  # Extract date part and truncate to YYYYMMDD format\n","    return pd.to_datetime(date_str, format='%Y%m%d').date()\n","\n","def get_overlapping_sar_file(olci_filename, get_S3_SI_search_results_df, token):\n","    olci_date = get_date_from_olci_filename(olci_filename)\n","    start_date = olci_date - pd.Timedelta(days=1)\n","    end_date = olci_date + pd.Timedelta(days=1)\n","    dates = pd.date_range(start_date, end_date)\n","\n","    all_overlapping_sar = pd.DataFrame()  # Collect all overlapping SAR files\n","\n","    for date in dates:\n","        date = date.tz_localize('UTC')\n","        search_results_df = get_S3_SI_search_results_df(date)\n","\n","        if search_results_df.empty:\n","            print(f\"No SAR data found for date: {date}\")\n","            continue\n","\n","        filtered_df = filter_duplicate_products_versions(search_results_df)\n","        if filtered_df.empty:\n","            print(f\"No SAR data after filtering for date: {date}\")\n","            continue\n","\n","        overlapping_sar = find_overlapping_sar(olci_filename, filtered_df)\n","        if not overlapping_sar.empty:\n","            all_overlapping_sar = pd.concat([all_overlapping_sar, overlapping_sar], ignore_index=True)\n","\n","    return all_overlapping_sar\n","\n","from datetime import datetime\n","\n","def check_overlap(row, olci_filename, olci_start, olci_end):\n","    \"\"\"\n","    Checks if the SAR file's sensing period overlaps with the OLCI file's sensing period and if it's from the same satellite.\n","\n","    Parameters:\n","    row (Series): A row from the SAR search results DataFrame.\n","    olci_filename (str): The OLCI filename.\n","    olci_start (datetime): Start time of OLCI sensing period.\n","    olci_end (datetime): End time of OLCI sensing period.\n","\n","    Returns:\n","    bool: True if there's an overlap and the satellite is consistent, False otherwise.\n","    \"\"\"\n","    # Extract satellite identifier from the OLCI filename\n","    satellite = olci_filename.split('_')[0]  # e.g., S3A or S3B\n","\n","    # Parse SAR start and end times\n","    sar_start = datetime.strptime(row['ContentDate']['Start'], '%Y-%m-%dT%H:%M:%S.%fZ')\n","    sar_end = datetime.strptime(row['ContentDate']['End'], '%Y-%m-%dT%H:%M:%S.%fZ')\n","\n","    # Check for temporal overlap and satellite consistency\n","    is_temporal_overlap = sar_start <= olci_end and sar_end >= olci_start\n","    is_same_satellite = satellite in row['Name']\n","\n","    return is_temporal_overlap and is_same_satellite\n","\n","# Adjust the find_overlapping_sar function to include the OLCI filename in the check_overlap call\n","def find_overlapping_sar(olci_filename, search_results_df):\n","    # Extract date and time from OLCI filename\n","    parts = olci_filename.split('_')\n","    olci_sensing_start = datetime.strptime(parts[7], '%Y%m%dT%H%M%S')\n","    olci_sensing_end = datetime.strptime(parts[8], '%Y%m%dT%H%M%S')\n","\n","    # Filter for SAR files that overlap with the OLCI sensing period\n","    overlapping_sar = search_results_df[search_results_df.apply(lambda row: check_overlap(row, olci_filename, olci_sensing_start, olci_sensing_end), axis=1)]\n","\n","    return overlapping_sar\n","\n","\n","\n"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"sPbKhR6wOYm9","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1706873621008,"user_tz":0,"elapsed":30440,"user":{"displayName":"Skylar Park","userId":"17855320419104885667"}},"outputId":"d5022794-d07b-4a8a-9cc4-b1aad77beab5"},"outputs":[{"output_type":"stream","name":"stdout","text":["Downloaded: /content/drive/MyDrive/GEOL0069/Week_4/Data/S3B_SR_2_LAN_SI_20190301T231304_20190301T233006_20230405T162425_1021_022_301______LN3_R_NT_005.SEN3.zip\n"]}],"source":["# Example usage\n","\n","token, refresh_token = get_access_token(username, password)\n","olci_filename = s3_olci_data['Name'][0] ## This is an example, which you should replace with the one you are interested in.\n","overlapped_df = get_overlapping_sar_file(olci_filename, get_S3_SI_search_results_df, token)\n","product_id = overlapped_df['Id'].iloc[0]\n","file_name = overlapped_df['Name'].iloc[0]\n","download_dir = '/content/drive/MyDrive/GEOL0069/Week_4/Data'\n","download_single_product(product_id, file_name, token, download_dir)"]},{"cell_type":"markdown","metadata":{"id":"N7sBPy2YOYm9"},"source":["We've now gathered Sentinel-2 optical data, Sentinel-3 OLCI, and altimetry data, enabling us to advance into a comprehensive analysis leveraging their combined strengths."]},{"cell_type":"code","source":[],"metadata":{"id":"9vcYaccQlcAN"},"execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3.10.13 ('s3s2_env')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"ea7d6a51bd5bebc5530766074a327a4db30535c2e45ca3d8f95c2d659fc0ffa4"}},"colab":{"provenance":[]}},"nbformat":4,"nbformat_minor":0}